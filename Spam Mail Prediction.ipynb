{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df8d70e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer #to convert the text into vector\n",
    "from sklearn.linear_model import  LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6bdbe23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the data from csv file to a pandas Dataframe\n",
    "raw_mail_data = pd.read_csv('mail_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75bf30d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Category                                            Message\n",
      "0         ham  Go until jurong point, crazy.. Available only ...\n",
      "1         ham                      Ok lar... Joking wif u oni...\n",
      "2        spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3         ham  U dun say so early hor... U c already then say...\n",
      "4         ham  Nah I don't think he goes to usf, he lives aro...\n",
      "...       ...                                                ...\n",
      "5567     spam  This is the 2nd time we have tried 2 contact u...\n",
      "5568      ham               Will Ã¼ b going to esplanade fr home?\n",
      "5569      ham  Pity, * was in mood for that. So...any other s...\n",
      "5570      ham  The guy did some bitching but I acted like i'd...\n",
      "5571      ham                         Rofl. Its true to its name\n",
      "\n",
      "[5572 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(raw_mail_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "847e50d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the null values with a null string\n",
    "mail_data = raw_mail_data.where((pd.notnull(raw_mail_data)),'')#yahan per double comma ka use nahi karna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "365e8bdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Category                                            Message\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# printing the first 5 rows of the dataframe\n",
    "mail_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d29b0562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the number of rows and columns in the dataframe\n",
    "mail_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbf8351",
   "metadata": {},
   "source": [
    "# Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c72f0eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label spam mail as 0;  ham mail as 1;\n",
    "\n",
    "mail_data.loc[mail_data['Category'] == 'spam', 'Category',] = 0\n",
    "mail_data.loc[mail_data['Category'] == 'ham', 'Category',] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d183044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separating the data as texts and label\n",
    "\n",
    "X = mail_data['Message']\n",
    "\n",
    "Y = mail_data['Category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4cf5f143",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7b2bded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572,)\n",
      "(4457,)\n",
      "(1115,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b5d0db",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb26aed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the text data to feature vectors that can be used as input to the Logistic regression\n",
    "feature_extraction = TfidfVectorizer(min_df = 1, stop_words='english', lowercase='True')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ae4f94",
   "metadata": {},
   "source": [
    "TfidfVectorizer() basically give the value of the words.for example agar ak word 1000 dafa repeat ho raha hai tu ye us ko high value dy ga aur agar koe word 100 times aya hai tu ye us ko low value dy ga. infact her word ko ak value assign kar dy ga. \n",
    "min_df=1 (is ka matalb hai k humary data mien agar word ak daga aya hai tu us ko ignor kar do)means words count more then one hona chahy\n",
    "stop_words='english' jetni b stopwords ay hain un ko be ignor kar do.\n",
    "lowercase=true   sb words ko lower case mien convert kar do"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c567e49c",
   "metadata": {},
   "source": [
    "#ab hum X_train aur X_test ko numbers mien convert karien gy. Y_train,Y_test already number ki form mien hain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d816d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_features = feature_extraction.fit_transform(X_train)\n",
    "X_test_features = feature_extraction.transform(X_test)\n",
    "#basically yahan per do kam ho rahy hain ye humary data sayy  feature extraction using tfidfvectorizer find kar raha hai\n",
    "#aur sath mien us ko trasform b kar raha hai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e4897fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert Y_train and Y_test values as integers\n",
    "\n",
    "Y_train = Y_train.astype('int')\n",
    "Y_test = Y_test.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81a3eb37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 5413)\t0.6198254967574347\n",
      "  (0, 4456)\t0.4168658090846482\n",
      "  (0, 2224)\t0.413103377943378\n",
      "  (0, 3811)\t0.34780165336891333\n",
      "  (0, 2329)\t0.38783870336935383\n",
      "  (1, 4080)\t0.18880584110891163\n",
      "  (1, 3185)\t0.29694482957694585\n",
      "  (1, 3325)\t0.31610586766078863\n",
      "  (1, 2957)\t0.3398297002864083\n",
      "  (1, 2746)\t0.3398297002864083\n",
      "  (1, 918)\t0.22871581159877646\n",
      "  (1, 1839)\t0.2784903590561455\n",
      "  (1, 2758)\t0.3226407885943799\n",
      "  (1, 2956)\t0.33036995955537024\n",
      "  (1, 1991)\t0.33036995955537024\n",
      "  (1, 3046)\t0.2503712792613518\n",
      "  (1, 3811)\t0.17419952275504033\n",
      "  (2, 407)\t0.509272536051008\n",
      "  (2, 3156)\t0.4107239318312698\n",
      "  (2, 2404)\t0.45287711070606745\n",
      "  (2, 6601)\t0.6056811524587518\n",
      "  (3, 2870)\t0.5864269879324768\n",
      "  (3, 7414)\t0.8100020912469564\n",
      "  (4, 50)\t0.23633754072626942\n",
      "  (4, 5497)\t0.15743785051118356\n",
      "  :\t:\n",
      "  (4454, 4602)\t0.2669765732445391\n",
      "  (4454, 3142)\t0.32014451677763156\n",
      "  (4455, 2247)\t0.37052851863170466\n",
      "  (4455, 2469)\t0.35441545511837946\n",
      "  (4455, 5646)\t0.33545678464631296\n",
      "  (4455, 6810)\t0.29731757715898277\n",
      "  (4455, 6091)\t0.23103841516927642\n",
      "  (4455, 7113)\t0.30536590342067704\n",
      "  (4455, 3872)\t0.3108911491788658\n",
      "  (4455, 4715)\t0.30714144758811196\n",
      "  (4455, 6916)\t0.19636985317119715\n",
      "  (4455, 3922)\t0.31287563163368587\n",
      "  (4455, 4456)\t0.24920025316220423\n",
      "  (4456, 141)\t0.292943737785358\n",
      "  (4456, 647)\t0.30133182431707617\n",
      "  (4456, 6311)\t0.30133182431707617\n",
      "  (4456, 5569)\t0.4619395404299172\n",
      "  (4456, 6028)\t0.21034888000987115\n",
      "  (4456, 7154)\t0.24083218452280053\n",
      "  (4456, 7150)\t0.3677554681447669\n",
      "  (4456, 6249)\t0.17573831794959716\n",
      "  (4456, 6307)\t0.2752760476857975\n",
      "  (4456, 334)\t0.2220077711654938\n",
      "  (4456, 5778)\t0.16243064490100795\n",
      "  (4456, 2870)\t0.31523196273113385\n"
     ]
    }
   ],
   "source": [
    "print(X_train_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ad08f8",
   "metadata": {},
   "source": [
    "# Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc2bfc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c838388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training the Logistic Regression model with the training data\n",
    "model.fit(X_train_features, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "95fd6572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction on training data\n",
    "\n",
    "prediction_on_training_data = model.predict(X_train_features)\n",
    "accuracy_on_training_data = accuracy_score(Y_train, prediction_on_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b19313b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data :  0.9670181736594121\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy on training data : ', accuracy_on_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e17c2b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction on test data\n",
    "\n",
    "prediction_on_test_data = model.predict(X_test_features)\n",
    "accuracy_on_test_data = accuracy_score(Y_test, prediction_on_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e6b61379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data :  0.9659192825112107\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy on test data : ', accuracy_on_test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941e22d7",
   "metadata": {},
   "source": [
    "# Building a Predictive System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4bd17a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "Ham mail\n"
     ]
    }
   ],
   "source": [
    "input_mail = [\"I've been searching for the right words to thank you for this breather. I promise i wont take your help for granted and will fulfil my promise. You have been wonderful and a blessing at all times\"]\n",
    "\n",
    "# convert text to feature vectors\n",
    "input_data_features = feature_extraction.transform(input_mail)\n",
    "\n",
    "# making prediction\n",
    "\n",
    "prediction = model.predict(input_data_features)\n",
    "print(prediction)\n",
    "\n",
    "\n",
    "if (prediction[0]==1):\n",
    "  print('Ham mail')\n",
    "\n",
    "else:\n",
    "  print('Spam mail')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ca2ece",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
